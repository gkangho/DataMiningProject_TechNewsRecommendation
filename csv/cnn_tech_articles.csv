URL,Title,Author,Publication Date,Content
https://edition.cnn.com/2024/11/05/tech/xxl-tv-trend-best-buy/index.html,Super giant TVs are flying off store shelves | CNN Business,Jordan Valinsky,2024-11-05,"One of the biggest gifts this holiday season won’t fit under the tree, the chimney or even in some homes.
Televisions that measure 97 inches (and more) diagonally across – a.k.a. XXL TVs – are becoming a huge hit as the cost of giant screens sinks sharply, and viewers look to replace the screens they bought during the peak of the pandemic a few years ago.
Sales of gigantic screens are a bright spot for the TV manufacturing industry, amid stagnant sales for the overall category, according to research firm Circana.
Best Buy is adding XXL TVs to 70% of its 940 stores in the United States in response to demand from its customers, the country’s largest electronics retailer recently announced.
Because of improving technology and cheaper prices of components and manufacturing, prices for 98-inch TVs have fallen 53% compared to a year ago, a Circana spokesperson told CNN. Sales have soared 877% over the past year. By contrast, prices for televisions 75 inches through 96 inches have declined 6% with sales up just 19% this year.
Ultra-large televisions still aren’t cheap: Many of the options range in price between $1,699 to $2,999, and Best Buy is offering free delivery plus installation with purchase.
Still, the growing popularity of XXL TVs could help Best Buy climb out of a series of downbeat quarters. The company and its rivals have been hurt by customers cutting back on discretionary spending because of inflation. Best Buy CEO Corie Barry said in the company’s most recent earnings release that customers are “willing to spend on high price point products when they need to or when there is new compelling technology.”
“We’re seeing growing interest from shoppers in XXL TVs, especially as the technology gets better and more options are available at a variety of prices,” Blake Hampton, senior vice president of merchandising at Best Buy, said in a release.
Target, Costco and Walmart also have similar XXL TVs on sale ahead of the holiday season.
Related article
Everything seems more expensive, so why is a big new TV cheaper than ever?
XXL TVs are mirroring the growth of what four years ago were considered extra-large televisions: 65-inch models that customers scooped up during the pandemic. Stuck at home, many people upgraded their televisions in 2020 so they could experience bigger and better picture quality.
Since then, TV sales have slumped badly. But with those now-four-year old televisions starting to get long in the tooth for some impatient customers, XXL TVs represent an attractive upgrade.
“The strong growth trend for ultra-large TVs aligns with the increase in 65-inch TV sales from 2018 to 2020, which consumers are now starting to replace five to six years later, in line with what our research suggests is the most common replacement interval,” Paul Gagnon, Circana’s vice president for consumer technology, said in a recent report. “We expect this trend to persist as upgrade activity continues into 2025 and beyond.”
One particular feature of interest for buyers is the multi-view option. Rather than squinting at several different sports happening at once, a 97-inch TV splits the screen up into four, 48-inch boxes making it easier to watch the different events, Best Buy said."
https://edition.cnn.com/2024/11/04/tech/elon-musk-town-hall-x-technical-problems/index.html,Elon Musk cancels X town hall event minutes after it started following yet another round of technical problems | CNN Business,Clare Duffy,2024-11-05,"Elon Musk on Monday held a digital version of the town-hall-style rallies he has hosted on behalf of former President Donald Trump. But the event on X ended just a few minutes after it started, when Musk encountered technical difficulties.
The event began streaming more than 20 minutes after its scheduled 8 p.m. ET start time. When the billionaire X owner joined, he promoted a podcast interview he did with Joe Rogan and offered to take questions. An operator then attempted to take questions from four listeners who apparently had been on hold, but the line went silent when he called on them.
The operator asked Musk if he believes “we will win” on Tuesday – presumably referring to Trump, whom Musk has supported to the tune of tens of millions of dollars.
“Well, I think if people vote tomorrow, we’re definitely going to win,” he said.
Musk then called off the event, saying, “Let’s cancel this, since we seem to be having some technical issues.” Musk promised to start a regular livestream Spaces event on X. The X Spaces event Musk started immediately following the town hall, lasted one minute and appeared to have no audio.
Minutes later, Musk turned his attention instead to a social media-famous squirrel that was euthanized over the weekend. He also said he would not restart his Q&A and encouraged followers to listen to his Rogan interview instead. Rogan endorsed Trump in an X post promoting the episode Monday night.
The Monday night town hall marks just the latest election-related event that Musk attempted to host on X that was plagued by technical difficulties.
An August interview between Musk and Trump that was streamed on X was delayed by more than 40 minutes because of glitches. Musk blamed the issue on a cyberattack, but some experts speculated it was simply caused by too many users trying to listen. A similar event last year to kick off Florida Gov. Ron DeSantis’ presidential campaign was also delayed by 25 minutes and marred by technical difficulties."
https://edition.cnn.com/2024/11/12/tech/ai-deepfake-porn-advice-terms-of-service-wellness/index.html,AI means anyone can be a victim of deepfake porn. Here’s how to protect yourself | CNN Business,Clare Duffy,2024-11-12,"“All we have to have is just a human form to be a victim.” That’s how lawyer Carrie Goldberg describes the risk of deepfake porn in the age of artificial intelligence.
While revenge porn — or the nonconsensual sharing of sexual images — has been around for nearly as long as the internet, the proliferation of AI tools means that anyone can be targeted by this form of harassment, even if they’ve never taken or sent a nude photo. Artificial intelligence tools can now superimpose a person’s face onto a nude body, or manipulate existing photos to make it look as if a person is not wearing clothes.
In the past year, targets of AI-generated, nonconsensual pornographic images have ranged from prominent women like Taylor Swift and Rep. Alexandria Ocasio-Cortez to high school girls.
For someone discovering that they, or their child, have been made the subject of deepfake porn, the experience is typically scary and overwhelming, said Goldberg, who runs the New York-based firm C.A. Goldberg Law representing victims of sex crimes and online harassment. “Especially if they’re young and they don’t know how to cope and the internet is this big, huge, nebulous place,” she said.
But there are steps that targets of this form of harassment can take to protect themselves and places to turn for help, Goldberg told me in an interview on CNN’s new tech podcast, Terms of Service with Clare Duffy.
Terms of Service aims to demystify the new and emerging technologies that listeners encounter in their daily lives. (You can listen to the full conversation with Goldberg here.)
Goldberg said that for people targeted by AI-generated sexual images, the first step — however counterintuitive — should be to screenshot them.
“The knee-jerk reaction is to get this off the internet as soon as possible,” Goldberg said. “But if you want to be able to have the option of reporting it criminally, you need the evidence.”
Next, they can seek out the forms that platforms like Google, Meta and Snapchat provide to request removal of explicit images. Nonprofit organizations like StopNCII.org and Take It Down can also help facilitate the removal of such images across multiple platforms at once, although not all sites cooperate with the groups.
A bipartisan group of senators sent an open letter in August calling on nearly a dozen tech firms, including X and Discord, to join the programs.
The fight to address nonconsensual explicit images and deepfakes has received rare bipartisan support. A group of teens and parents who had been affected by AI-generated porn testified at a hearing on Capitol Hill, where Republican Sen. Ted Cruz introduced a bill — supported by Democratic Sen. Amy Klobuchar and others — that would make it a crime to publish such images and require social media platforms to remove them upon notice from victims.
But, for now, victims are left to navigate a patchwork of state laws. In some places, there are no criminal laws preventing the creation or sharing of explicit deepfakes of adults. (AI-generated sexual images of children typically fall under child sexual abuse material laws.)
“My proactive advice is really to the would-be offenders which is just, like, don’t be a total scum of the earth and try to steal a person’s image and use it for humiliation,” Goldberg said. “There’s not much that victims can do to prevent this … We can never be fully safe in a digital society, but it’s kind of up to one another to not be total a**holes.”"
https://edition.cnn.com/2024/10/31/tech/google-fines-russia/index.html,"Russia fines Google $20,000,000,000,000,000,000,000,000,000,000,000 | CNN Business",Hanna Ziady,2024-10-31,"Russia is seeking an unfathomable sum of money from one of the world’s biggest tech companies.
Google reportedly owes the Kremlin more than 2 undecillion rubles — a 2 followed by 36 zeroes — after refusing to pay fines that are now accruing for blocking pro-Russian channels on YouTube.
The virtually unpronounceable penalty amounts to $20 decillion — or around $20 billion trillion trillion. That dwarfs the size of the global economy.
At $110 trillion, according to International Monetary Fund figures, world gross domestic product looks modest in comparison. Google parent Alphabet, meanwhile, has a market value of around $2 trillion.
Russian state media TASS reported this week that a Russian court had earlier ordered Google to restore the YouTube channels — several of which have been blocked since 2022 — or else face mounting charges, with penalties doubling every week.
Asked about the lawsuit during a call with reporters Thursday, Kremlin spokesman Dmitry Peskov admitted that he “can’t even pronounce this figure right” but said that the eye-watering sum was “filled with symbolism.” Google “should not be restricting the actions of our broadcasters on its platform,” he added.
CNN has contacted Google for comment. In quarterly earnings published this week, the company referred to “ongoing legal matters” relating to its business in Russia.
“Civil judgments that include compounding penalties have been imposed upon us in connection with disputes regarding the termination of accounts, including those of sanctioned parties,” Google said. “We do not believe these ongoing legal matters will have a material adverse effect (on earnings).”
Following Russia’s full-scale invasion of Ukraine, Google curtailed operations in the country but stopped short of pulling out altogether, in contrast with several other American tech companies. Many of its services, including Search and YouTube, continue to be available in the country.
Months after the invasion, Google’s Russia subsidiary filed for bankruptcy and paused most of its commercial operations after the government seized control of its bank accounts."
https://edition.cnn.com/2024/10/30/tech/tiktok-founder-china-richest-intl-hnk/index.html,TikTok’s founder is now China’s richest person. But the country’s total number of billionaires has shrunk | CNN Business,Simone McCarthy,2024-10-30,"China has a new richest person – and it’s the entrepreneur behind the wildly popular, and controversial, app TikTok.
Zhang Yiming, 41, co-founder of TikTok’s parent company ByteDance, topped the 2024 Hurun China Rich List, released Tuesday. His wealth reached $49.3 billion, as assessed by research, media and investment group Hurun Inc, which publishes the ranking of the country’s richest people.
Zhang’s ascendency comes after ByteDance’s global revenue grew 30% last year to $110 billion, Hurun said.
Since its official launch in May 2017, TikTok has been catapulted to mass global popularity as well as becoming an era-defining social media platform beloved by many young people around the world – and a trailblazing example for other Chinese companies eager to break into US and global markets.
But it’s also now facing mounting legal battles in the US, where according to Hurun it has nearly 200 million users.
There, TikTok is battling state and federal lawsuits related to alleged failures to protect children using the app, while it and ByteDance are fighting a law that could force a nationwide ban of the app if TikTok doesn’t spin off its US operations.
The law – signed in April – follows years of US allegations that TikTok’s ties to China could potentially expose Americans’ personal information to the Chinese government. TikTok strongly denies the allegations, which come as a growing China-US rivalry has fueled broader American national security concerns about Chinese tech firms. TikTok has also rejected the allegations relating to child protection.
Other countries have also cited national security concerns, including India which has banned TikTok. Western allies such as Britain, Canada and Australia have restricted TikTok’s use on government devices.
But those regulatory hurdles have done little to dent TikTok’s growing global appeal among users.
Related article
Wait, is TikTok really Chinese?
Zhang owns 20% of ByteDance, which he co-founded with college roommate Liang Rubo in Beijing in 2012. He stepped down as its CEO 2021 after building ByteDance into one of the biggest names in Chinese tech.
ByteDance also holds China’s popular news app Toutiao and Douyin, TikTok’s sister app in China.
Zhang’s rise to the top of the rich list knocked China’s “bottled water king” Zhong Shanshan out of the lead spot for the first time in three years, though he remained second.
Zhong faced a wave of online vitriol earlier this year from nationalists who accused him of a lack of patriotism in a campaign that hit the price of shares of his beverage company.
In third place was Pony Ma, founder of multimedia and entertainment giant Tencent, which owns China’s ubiquitous messaging and payments platform WeChat.
Overall, the number of US-dollar billionaires in China shrank to 753, down 142 from the previous year. China has also lost 432 or just over a third of its billionaires since a peak of 1,185 in 2021, Hurun said.
The number of people ranked on the list – 1,094 – also shrank overall for the third consecutive year. The list includes those individuals assessed to have at least 5 billion yuan (roughly $700 million) as of the end of August. The list also includes those living in Hong Kong and Macao as well as in the self-ruling democracy of Taiwan.
Hurun Report chairman Rupert Hoogewerf chalked the decline up to a “difficult year” for China’s economy and stock markets.
China is grappling with steep economic challenges, with a real estate crisis, high local government debt and lagging consumer spending among factors ratcheting global concern about the health and trajectory of the world’s second-largest economy.
“The number of individuals on the list was down by 12% in the past year to just under 1100 individuals and 25% from the high point of 2021, when we managed to find 1465 individuals with 5 billion (yuan),” he said in a statement.
“The old guard, represented by real estate developers, have given way to a new guard of tech, new energy, consumer electronics, especially smart phones, ecommerce, especially cross-border ecommerce, consumer products and healthcare,” he said."
https://edition.cnn.com/2024/11/04/tech/tiktok-sued-harmful-content-children-france/index.html,TikTok sued in France over harmful content that allegedly led to two suicides | CNN Business,,2024-11-04,"Seven French families have filed a lawsuit against social media giant TikTok, accusing the platform of exposing their adolescent children to harmful content that led to two of them taking their own lives at 15, their lawyer said Monday.
The lawsuit alleges TikTok’s algorithm exposed the seven teenagers to videos promoting suicide, self-harm and eating disorders, lawyer Laure Boutron-Marmion told broadcaster franceinfo.
The families are taking joint legal action in the Créteil judicial court. Boutron-Marmion said it was the first such grouped case in Europe.
“The parents want TikTok’s legal liability to be recognized in court,” she said, adding: “This is a commercial company offering a product to consumers who are, in addition, minors. They must, therefore, answer for the product’s shortcomings.”
Related article
‘There are no guardrails.’ This mom believes an AI chatbot is responsible for her son’s suicide
TikTok, like other social media platforms, has long faced scrutiny over the policing of content on its app.
Just like Meta (META) with Facebook and Instagram, it faces hundreds of lawsuits in the United States accusing the companies of enticing and addicting millions of children to their platforms, damaging their mental health.
TikTok could not immediately be reached for comment on the allegations.
The company has previously said it took issues that were linked to children’s mental health seriously. CEO Shou Zi Chew this year told US lawmakers the company has invested in measures to protect young people who use the app."
https://edition.cnn.com/2024/11/15/tech/fortyguard-urban-heat-ai-hnk-spc/index.html,Urban areas are getting hotter. A startup from one of the world’s hottest cities wants to help | CNN Business,Amy Gunia,2024-11-15,"Climate change is impacting urban areas especially hard, and densely populated cities are suffering the most.
The urban heat island effect means that city temperatures can be several degrees higher than nearby rural regions. That’s because materials like concrete and asphalt absorb and radiate heat. Vehicles and air-conditioning units expel heat, and towering buildings block wind flow.
Officials across the globe are trying to cool cities down. In Chicago, which has a history of fatal heatwaves, more than 500 rooftops have been covered with vegetation, which releases cooling water vapor and acts as natural insulation for the building. Los Angeles, which has a vast network of freeways, has painted some of its roads with a solar-reflective material.
But detailed information about urban temperatures is scarce. That became clear to entrepreneur Jay Sadiq soon after he founded a startup in Abu Dhabi to modify asphalt to absorb less heat, when a potential client encouraged him to identify the hottest parts of the city, where the material would be most beneficial.
Sadiq couldn’t find the level of granular data he needed, so he started working on harnessing the information himself. Today, his company FortyGuard is focused on leveraging data and artificial intelligence (AI) technology to provide a detailed view of urban temperature dynamics.
He hopes that it will enable urban planners, chief heat officers, businesses, and real estate developers to make data-driven decisions, and residents to better plan their lives.
Extreme heat can cause heat-related illnesses and death, particularly for vulnerable groups like young children and the elderly. Global heat-related mortality for people aged 65 and older increased approximately 85% between 2017 and 2021.
As billions of people move to urban areas in the coming decades, between half and three-quarters of the global population could be exposed to life-threatening extreme heat and humidity by 2100, according the UN’s Intergovernmental Panel on Climate Change.
Rising temperatures also makes it harder to sleep at night, and difficult to be productive during the day, especially for outdoor workers.
Although urban heat is gaining more attention, most weather stations haven’t been built to specifically address the issue, and they’re often located at an airport or atop a hillside – areas that aren’t representative of the temperature on a city sidewalk.
“Historically, most meteorological agencies would be tasked with monitoring the weather at scales larger than cities,” says James Voogt, a professor in the department of Geography and Environment at the University of Western Ontario, who is an expert in urban climatology.
Satellites that measure surface temperature can cover wide areas but can’t provide detailed information about neighborhood hotspots. And trees and tall buildings can block satellites from recording temperatures at ground level. “It doesn’t see the shade underneath,” says Voogt.
Some cities have started collecting information using sensors mounted on streetlights or buses, and others, including Hong Kong, have deployed dense urban meteorological networks. “But not many cities have such a dense measurement network,” says Chao Ren, an associate professor of architecture at the University of Hong Kong, who specializes in applied climatology and climate design.
FortyGuard, which today has 16 employees and offices in Abu Dhabi and San Jose, California, collects 32 billion data points daily from third-party providers, but Sadiq says he can’t reveal much about their sources, given market competition.
It then uses AI to produce models that take into account variables that impact how temperature is felt – including a city’s elevation, vegetation, water bodies, and atmospheric conditions, such as cloud cover, to give a fuller view of local temperature dynamics, he says. “Our approach goes beyond measuring air temperature at a specific point in time,” Sadiq adds.
Some of the company’s most robust information is about certain US cities, allowing it to model urban temperature for each 10 square meters, with 89% accuracy, according to Sadiq.
FortyGuard offers advisory services, and it has worked with clients like Masdar City, an experimental “sustainable city” in the United Arab Emirates, to help it pinpoint heat hotspots to add trees and water features.
Related article
Oil-rich Abu Dhabi wants to be an AI leader. Aligning with the US is just the start
But the startup, which is “about to about to close a large funding round,” is aiming to position itself as a technology company, says Sadiq. He hopes to integrate its technology into existing platforms, like a real estate or map platform. That could enable homebuyers to figure out the least hot neighborhood in a city, or runners to determine the best route for a morning run, he says.
Technology platforms are already incorporating climate-related information from other providers. In late September, US real estate website Zillow announced that its listings would feature information such as wildfire risk, air quality and heat.
Others are applying AI to urban heat issues. In September, Google announced a new Heat Resilience tool, which applies AI to aerial and satellite images to help cities deal with extreme heat.
Voogt and Ren said that it’s difficult to comment on FortyGuard’s urban heat intelligence without knowing more about its data sources, validation methods and technology. “The key element is how such AI is being trained and on what,” says Voogt.
But there is “definitely a need and demand for high spatial resolution temperatures in urban environments,” he adds.
Ren said what’s most important about urban heat information is how it will be used. While interest in urban heat is increasing, some places are doing better than others at addressing it, by educating residents about the issue, creating warning systems, or incorporating mitigation considerations into building codes or city planning.
“The question is really, who will be the end user of your data, and who will put such urban heat information into their practices?” she says."
https://edition.cnn.com/2024/10/29/tech/influencers-presidential-campaign-paid-disclosure/index.html,Influencers are playing a big role in the 2024 election. There’s no way to tell who’s getting paid for their endorsements | CNN Business,"Clare Duffy, Brian Fung",2024-10-29,"“There are only 22 days more to vote, so like seriously go vote … it’s so important to me that we mobilize our community to Pokémon Go to the polls,” influencer Mikey Angelo, who’s known online for his comedic rap videos, said in a recent Instagram video.
Angelo was paid by a Democratic political action committee for the post, a fact that’s clearly noted in the caption. But he didn’t legally have to disclose the relationship.
Partnerships with influencers have become an increasingly popular campaign strategy. But a regulatory gap means that unlike political ads that run on TV — or typical sponsored content that influencers post for brands — content creators are not required to disclose if they’ve been paid to endorse a candidate or speak about a political issue on their page.
A campaign can post a video on its own platforms and then pay an influencer to promote it, or pay an individual to create his or her own promotional material for a candidate, without the campaign or influencer having to disclose anything, the Federal Election Commission determined earlier this year.
That means users are often left to try to judge for themselves which posts are paid endorsements versus creators’ genuine, freely shared expressions of support when they’re mixed together in feeds — along with the regular collection of normal posts and non-political #sponcon — sometimes, with no indication of which is which.
And that could further complicate an already muddy information ecosystem, at a time when nearly 40% of young Americans say they regularly get their news from TikTok and when US adults under 30 are nearly as likely to trust information from social media as from national news outlets, according to the Pew Research Center.
In 2024, political content posted by social media creators has become just as important as traditional celebrity endorsements — if not more. Influencers often have huge, engaged followings who trust them because they bring a sense of authenticity that traditional celebrities, like actors and entertainers, lack.
And politicians want to take advantage of that. If influencers’ vast followings already take their advice on everything from dietary supplements to parenting, politics could be added to the mix, too.
“Influencers might not seem as professionally curated as trained actors and actresses,” said Krysten Stein, an assistant professor of communication at the University of Cincinnati Blue Ash College.
“We tend to trust people who are more real or more like us,” she said. “And then if they endorse a candidate, well, ‘Hey, they’re kind of like me. We have similar interests or are from a similar place.’ So, sure, I might trust them more.”
In July, between posts about vacations, his nascent boxing career and his body wash brand, influencer Jake Paul posted an Instagram video showing him play-fighting with former President Donald Trump. “We need Trump to knockout all his opponents on Election Day,” Paul said in the caption of the video, which racked up more than 1.5 million likes.
Last month, Democratic vice presidential nominee Tim Walz appeared in a YouTube video going for a walk with his dog, Scout, and Matt Nelson, the human behind the popular channel We Rate Dogs. The video, which served as a sort of get-to-know-you opportunity for Walz, gained more than 600,000 views on YouTube; a clip posted to X was viewed more than 1.5 million times. (A representative for Nelson said he was not paid for the video; Paul also was not compensated for his appearance with Trump, according to a person familiar with his business.)
This year’s Democratic National Convention also provided media credentials to more than 200 influencers, along with a cushy “creator lounge” from which to post content about Vice President Kamala Harris’ White House bid.
Angelo’s post is part of a $2.7 million digital campaign from Democratic political action committee Priorities USA, which has contributed to election efforts for Harris, and voter engagement PAC Somos Votantes. Together, the two organizations paid 15 social media creators to produce content encouraging Latinos to vote. (Angelo did not respond to a request for comment.)
“It’s no surprise that in a political environment, when our No. 1 job is to have our message resonate and break through and be trusted, that working with content creators who already have trust built up with their followers just makes a lot of sense,” said Danielle Butterfield, executive director of Priorities USA, which has also run influencer campaigns around local elections and progressive issues like reproductive rights.
Priorities typically works with influencer marketing agencies to determine how much to pay a creator, Butterfield told CNN. But the organization leaves partnership and payment disclosures up to the creators themselves.
“We’re working with a lot of folks who haven’t done political work before, so there’s often a little bit of confusion around, ‘Oh, I don’t have to disclose? That’s not the law?’ So we often have to explain that [there is no disclosure law,],” Butterfield said. “We walk the creators through what the rules are and then we leave it up to them to determine how they want to post their content.”
In the second half of 2020, Trump’s then-reelection campaign paid nearly $1.8 million to an influencer marketing business, Axios reported in early 2021, citing Federal Election Commission filings.
Also on the right, conservative group Turning Point USA has a yearslong history of training and promoting influencers — its website touts partnerships with the likes of right-wing activist Jack Posobiec and Riley Gaines, the former NCAA swimmer who has opposed including transgender athletes in women’s sports — to spread its message.
And Tana Mongeau, a YouTuber with more than 5 million subscribers, suggested during an episode of her podcast last month that she was offered “millions” to endorse an unnamed political party on social media. Mongeau had already publicly backed Harris, implying that the offer came from elsewhere. Mongeau spoke in vague terms about the endorsement offer, but indicated that she’d turned down the money.
“I was being allegedly told and alleged list of other influencers that have already, hypothetically, accepted money to do those hypothetical things,” Mongeau said. (Spokespeople for Mongeau didn’t respond to CNN’s requests for an interview.)
The Harris campaign declined to comment for this piece. The Trump campaign, as well as the Democratic National Committee and Republican National Committee, did not respond to requests for comment.
The Federal Trade Commission in 2019 laid out new guidelines for social media influencers, requiring them to clearly label posts for which they’d been paid to promote a product or company, by adding a disclosure such as #ad or #sponsored in the caption. But by law, the FTC’s rules can cover content related only to “commerce,” said spokesperson Mitchell Katz, citing agency guidance.
Election advertisements are overseen by a different agency, the Federal Elections Commission, which lacks a similar disclosure rule for individuals who are paid to make endorsements on social media. The FEC does have strict transparency rules around paid political communications over the phone, on TV or on physical mailers — everyone is familiar with those “paid for by” disclosures — but those requirements don’t apply to influencers.
The FEC had the opportunity last year to extend its rules to influencers, but chose not to, saying that campaign payments to individuals fell outside the scope of a broader package of regulations for ads involving payments to a “website, digital device, application, or advertising platform.”
The commission determined that campaign payments to creators to produce political messaging are not “public communications” that would require disclosure.
Despite voting for the overall package, two FEC commissioners dissented over the decision on influencers, saying the agency “missed a golden opportunity” to issue clear guidance on a growing means of political communication.
“The public is entitled to know when those influencers are being paid to spread a political message,” wrote Commissioners Ellen Weintraub and Shana Broussard, who were appointed by former Presidents George W. Bush and Trump, respectively.
In the absence of federal regulations, some platforms have instituted their own rules, although enforcing them may be tricky if creators aren’t up-front about their relationships with political groups.
Meta, the parent company of Facebook and Instagram, has since 2020 allowed paid political content from influencers, so long as the organization paying for it is registered in its ad library. TikTok says it does not allow any political advertising, even from creators. TikTok removed one video that was labeled as part of the Priorities USA and Somos Votantes campaign after CNN flagged it to the platform.
Critics say that if individuals were required to disclose paid political posts, it could have unintended consequences for political speech — especially when any payments to influencers should already be reflected in the campaigns’ own routine expenditure reports.
The FEC should take steps to make it easier for the public to access this information before cracking down on creators, said Ari Cohn, a First Amendment law expert at the think tank and advocacy group TechFreedom.
“I don’t want to live in a world where to be able to post things about politics online, I have to consult a lawyer first,” Cohn said, adding that although the FEC says the current rules don’t apply to influencers, a future FEC could easily come to the opposite interpretation.
While politicians can and should try to reach voters where they are, the advent of new technologies doesn’t change campaigns’ underlying obligation to behave ethically on those platforms, said Robert Weissman, co-president of Public Citizen, an accountability non-profit.
“It makes all the sense in the world for campaigns to pitch themselves to influencers and ask them to carry forward their message,” Weissman said. “If it’s a financial transaction, though, it’s vital that the money flow be disclosed, that people know the influencers are taking action because they’ve been paid, not just out of belief.”
To be sure, not every creator is quietly earning money for weighing in on the election. There are likely plenty of cases where creators aren’t being paid for posting but are just “already really engaged” in the political conversation, said Cate Domino, a senior vice president for digital at Precision Strategies, a Democratic consulting firm.
Campaigns may know “which messages are super important, but they’re having trouble getting to resonate with the right audiences,” so they partner with politically engaged creators to “help us get this message out,” said Domino, who added that her firm does not work directly with the Harris campaign.
“There is something in it for the creator too, right?” she said. “If the campaign is lifting up their content, that’s them reaching a whole host of people who — especially if you’re a creator who’s known for your advocacy work — probably like really align with the content that you’re putting out.”"
https://edition.cnn.com/2024/11/14/tech/meta-fine-europe-facebook-marketplace-intl/index.html,Europe fines Meta $840 million over practices benefiting Facebook Marketplace | CNN Business,,2024-11-14,"The European Union has fined Meta Platforms €798 million ($840 million) over what it called abusive practices benefiting Facebook Marketplace.
“The European Commission has fined Meta … for breaching EU antitrust rules by tying its online classified ads service Facebook Marketplace to its personal social network Facebook and by imposing unfair trading conditions on other online classified ads service providers,” the EU’s executive arm said in a statement.
Meta (META) said it will appeal the decision, but in the meantime, it will comply and will work quickly and constructively to launch a solution that addresses the points raised.
The move by the European Commission comes two years after it accused the US tech giant of giving its classified ads service Facebook Marketplace an unfair advantage by bundling the two services together.
Related article
Meta accused of breaking European law with its ‘pay or consent’ model
The European Union opened formal proceedings into possible anticompetitive conduct of Facebook in June 2021, and in December 2022 raised concerns that Meta ties its dominant social network Facebook to its online classified ad services.
Facebook launched Marketplace in 2016 and expanded into several European countries a year later.
The EU decision argues that Meta imposes Facebook Marketplace on people who use Facebook in an illegal “tie” but Meta said that argument ignores the fact that Facebook users can choose whether to engage with Marketplace, and many do not.
Meta said the European Commission claimed that Marketplace had the potential to hinder the growth of large incumbent online marketplaces in the EU but could not find any evidence of harm to competitors.
Companies risk fines of as much as 10% of their global turnover for EU antitrust violations."
https://edition.cnn.com/2024/11/05/tech/social-media-election-ads-pause-misinformation/index.html,Google and Meta are blocking political ads to combat misinformation. Some experts say it’s too late | CNN Business,Clare Duffy,2024-11-05,"Facebook, Instagram, Google and YouTube are clamping down on political ads in an effort to combat misinformation that could undermine trust in the results of a contentious election or stir up unrest.
Meta last week began blocking advertisers from creating or running new ads about US social issues, elections or politics across its platforms, including Facebook and Instagram. Meta’s ban of new political advertising was initially set to expire Tuesday night, but on Monday the company extended it until later this week. Google says it will implement a similar, temporary pause on ads related to US elections after the last polls close on Tuesday, set to remain in place for an unspecified period of time. TikTok has not allowed political ads since 2019.
In contrast, X ended its ban on political advertising last year after billionaire Elon Musk took over the platform and has not announced any pause around the election.
The election ad pauses are designed to prevent candidates or their supporters from attempting to sway public sentiment or claim early victory during what could be a days-long period of uncertainty around the results as ballots are counted. But experts say that previous moves by social media companies — such as cutting their own internal safety teams — could undercut their current efforts.
The pauses on some ads come as election officials have already spent weeks trying to combat viral misinformation about the election, including uncorroborated allegations of machines flipping votes and claims of widespread fraud in mail ballots. It also comes as federal law enforcement officials have warned that domestic extremists with “election-related grievances,” such as a belief in voter fraud despite a lack of proof, could engage in violence following the election.
Related article
Elon Musk’s misleading election claims have been viewed more than 2 billion times on X, analysis finds
Former President Donald Trump and many of his supporters have already made repeated false claims that Democrats are cheating in the election. What’s more, the proliferation of artificial intelligence tools has raised concerns that fake images, video or audio could be used in an effort to lend legitimacy to election rumors and false claims.
But while political advertising pauses mark just one of the steps tech platforms say they are taking to safeguard the online information ecosystem during election week, after cutting their own trust and safety teams and walking back election-related policies, experts say it may be too late to stop the flood of misinformation that has already permeated much of the internet from continuing to spread.
That’s especially true now that X (formerly Twitter) and its relatively new owner Musk have become some of the top purveyors of false and misleading election claims. Twitter was considered a leader in combating political misinformation and violent rhetoric before Musk bought it, with bigger players even following its example — like when it blocked then-President Donald Trump following the January 6, 2021, attack on the US Capitol.
“Since the last presidential election, we’ve seen a dramatic backslide in social media companies’ preparedness, enforcement and willingness to protect information online related to the election, related to candidates, politicians,” said Sacha Haworth, executive director of the watchdog group Tech Oversight Project, at an event hosted by the organization Monday. “Platforms are hotbeds for false narratives.”
The months leading up to the election brought a flood of misinformation that experts say is likely to undermine confidence in the electoral process.
“Over the last four years, we have had the drip, drip of lies about our electoral process, the operation of democracy and our elections,” Imran Ahmed, CEO of the social media watchdog group Center for Countering Digital Hate, told CNN Monday. “It’s too late.”
In the wake of online interference in the 2016 election and then again following the January 6, 2021, attack on the US Capitol, which was largely organized online, many big platforms beefed up their trust and safety and election integrity teams and policies, including by removing posts and suspending thousands of accounts that spread lies.
But since then, those companies have made cuts to those teams and walked back policies designed to restrict false claims about politics and elections. Last year, they said they would no longer remove false claims that the 2020 election was stolen.
The effects of that pullback — known among some industry watchers as “the backslide” — reached fever pitch over the summer when, following the first attempted assassination of Trump, conspiracy theories ran wild across social media. The spread of false claims about the response to hurricanes Helene and Milton, many of them targeted at the Biden-Harris administration, also threatened to hinder recovery efforts following those disasters, government officials and response agencies said.
On X, Musk’s false and misleading claims about the election — including about immigration and voting, and often in support of Trump, whom the billionaire campaigned for and donated to — generated more than 2 billion views this year, according to an analysis by Ahmed’s CCDH.
Ahmed said that as long as the platforms’ approach to false and misleading content remain the same, a temporary pause on political ads during election week is likely to have little impact.
“Stopping ads on platforms that are algorithmically designed to promote the most contentious information, whether that’s disinformation or hate, because of the high engagement it gets – they don’t need paid reach when they have platforms which organically are designed to promote their claims anyway,” Ahmed said.
Meta and X did not immediately respond to a request for comment regarding concerns that their election-week safety efforts may be inadequate.
TikTok pointed CNN to its “US Elections Integrity Hub,” where it says, “we protect election integrity on TikTok by preventing the spread of harmful content, connecting our community to authoritative information, and partnering with experts.
A YouTube spokesperson said in a statement that “Over the last few years, YouTube has heavily invested in the policies and systems that allow us to support elections, not just in the U.S. but around the world.”
They added: “Responsibility remains our number one priority, both during election time and year round. Content that misleads viewers or encourages interference in the democratic process is prohibited on YouTube. We quickly remove content that incites violence, encourages hatred, or promotes harmful conspiracy theories.”
Still, the major tech giants say they’re doing more than pausing election ads to safeguard their platforms. Facebook and Instagram, Google and YouTube, X and TikTok all say they have worked to elevate reliable information about the election, including by pointing users to state websites or neutral non-profits for information about voting, candidates and election results.
Most of the major platforms also say they have taken steps to prevent coordinated influence operations that could disrupt the election, including by foreign actors. Russian and Iranian operatives have attempted to sway US voters via online disinformation campaigns in recent months.
Related article
How Republicans pushed social media companies to stop fighting election misinformation
Leslie Miller, vice president of government relations at YouTube, which is owned by Google, laid out the platform’s plans for the election in a blog post last December, where she noted that YouTube does not allow content that misleads voters on how to vote or encourages election interference.
“We quickly remove content that incites violence, encourages hatred, promotes harmful conspiracy theories, or threatens election workers,” Mann said in the post.
TikTok says it does not allow content that could “result in voter interference, disrupt the peaceful transfer of power, or lead to off-platform violence,” including unverified or false claims about the final results of an election. The platform says it works with fact-checkers and will label other unverified claims and make them ineligible for promotion in its For You feed, such as “a premature claim that all ballots have been counted or tallied.”
Meta, likewise, says it removes content that could interfere with people’s ability to vote, such as threats about going to an election site to “monitor” and intimidate voters. With other content that its fact-checkers determine to be false, Meta says it will “move it lower in Feed” and label it to provide additional information for viewers.
Meta says it has no specific policy prohibiting non-ad content that declares early victory for a candidate before a vote has formally been called, although such posts could be eligible for a fact-check label. YouTube also will not prohibit videos declaring early victory for candidates, although it said such videos will display an informational panel with election results shared by the Associated Press.
In a statement to CNN, X said its Civic Integrity Policy, which prohibits false claims intended to manipulate or interfere in elections, such as content that could mislead people about how to vote or “lead to offline violence,” has been in effect in August. However, the policy explicitly allows for inaccurate statements about candidates, as well as “organic content that is polarizing, biased, hyperpartisan, or contains controversial viewpoints expressed about elections or politics.”
And, as is often the case with social media platforms’ policies, there is a difference between instituting a policy and enforcing it. Musk took heat in September for an X post seeming to question why “no one is even trying to assassinate Biden/Kamala,” which he later deleted and called a joke. Musk also appeared to violate a separate X policy when he shared a video last month on X that used AI to make it appear that Vice President Kamala Harris had said things she, in fact, did not."
https://edition.cnn.com/2024/11/13/tech/x-musk-bluesky-users-post-election/index.html,Bluesky’s user base has doubled in the past 90 days. Is it a mass exodus from X? | CNN Business,Clare Duffy,2024-11-13,"X competitor Bluesky rocketed to the No. 1 spot on the Apple App Store’s US chart this week, as many users of Elon Musk’s platform said they were decamping in the wake of his significant role in the US presidential election.
Bluesky’s user base has doubled in the past 90 days — on Tuesday the company said it had gained 1 million new sign-ups in the past week alone, bringing it to more than 15 million total users.
The energy on X is markedly different: Musk spent months using the site to boost President-elect Donald Trump. In recent days, researchers have recorded surges in sexist language like “your body, my choice” on the site. And that’s on top of previous changes by Musk, like cutting moderators, restoring banned accounts, allowing racist and Nazi accounts and changing the platform’s verification system to boost anyone who was willing to pay, regardless of what they posted — all of which helped to tank the company’s core ad business.
A number of prominent journalists announced their exit, accordingly, from X to join Bluesky this week, including the Atlantic’s Charlie Warzel, the New York Times’ Mara Gay and former CNN anchor Don Lemon. UK newspaper The Guardian also said Wednesday that it will no longer post to X from its official channels, calling X “a toxic media platform,” although it did not specify which other platforms it plans to use to promote its work.
But while Bluesky may be having A Moment three years after its launch, any claims that it will kill X should be taken with a grain of salt.
As a private company, X doesn’t share user numbers. Recent third party estimates of user trends are mixed, although the consistent user growth the platform enjoyed prior to Musk’s takeover does appear to have been upended in the past two years. But — for better or, probably, worse — the site has so far weathered the creation of multiple other competitors, the reinstatement of White supremacists and the spread of racist conspiracy theories from Musk down without fading into irrelevance.
“X usage is at an all-time high and continues to surge,” X CEO Linda Yaccarino said in a post Wednesday. “To all of our users — of every interest, political party, and point of view — You will always have a place to engage and join the global conversation freely and safely.”
More than 115,000 US X users deactivated their accounts the day after the election, the largest single-day exit since Musk assumed control of the platform, according to digital intelligence platform Similarweb. And that included only users who deactivated through the website, not the mobile app.
But X also had its highest web traffic all year that same day, racking up 46.5 million visits on desktop alone, up 38% from the average of the preceding few months, Similarweb said. Bluesky also saw daily visits jump on Election Day and the day after to 1.2 million and 1.3 million, respectively, up from around 800,000 in the days before.
“Whether there will be a measurable decrease in the audience for X as the result of politics remains to be seen,” David Carr, Similarweb editor of insights, news and research, said in a blog post Tuesday. But, he added, “X’s recent daily peak in US traffic doesn’t make up for the erosion in audience the service has seen over the past couple of years since Musk took ownership of the service.”
Sensor Tower, another market intelligence firm, found that daily active app users and time spent on X jumped on November 5 and 6 compared to the prior 30 days. But by November 10, X daily active users were relatively flat compared to just before the election, whereas Bluesky saw a 28% jump in users in the same period.
Related article
Tired of Elon Musk? Here are the Twitter alternatives you should know about
Still, X has far more users than Bluesky, Sensor Tower noted. (Bluesky also remains much smaller than Meta’s Threads.)
A third app data analysis firm, Apptopia, also told CNN that activity on X jumped significantly ahead of the election. It said X’s daily active users peaked days later, on November 9, before tapering off slightly. On Bluesky, daily users more than doubled from-mid October to the post-election week.
Here’s the takeaway from all those numbers: X had a big jump in usage leading up to and on Election Day and the day after, but it appears to be waning. At the same time, Bluesky saw a surge after the election that looks to be continuing, although its overall user base is still relatively small.
Of course, lots of people flock to all kinds of media during and around an election week. And it’s worth remembering that we’ve seen troves of users swear off X before in the wake of earlier Musk incidents, only for many of them to come trickling back to the platform.
Nonetheless, anecdotally, some prominent social media users say they’re now seeing more engagement with their posts — the thing users on these sites typically prize above all else — on Bluesky, despite having larger followings on X.
Ed Zitron, founder of media relations firm EZPR, told CNN he and others have remained on X “because there is a critical mass of readers on there and there is a virality to the content you post.”
But, Zitron said, “with how Bluesky is scaling right now, I don’t see how (X) stays dominant,” adding that he has 90,000 followers on X but “the actual engagement doesn’t seem to matching up.”
New York Times journalist Mike Isaac had a similar remark in a Bluesky post Tuesday: “real disorienting to go from twitter — where i do a post to 200k followers and get five favs — over to bluesky where a post gets like 200 favs immediately.”
But here’s the thing: Even if X was hemorrhaging users to Bluesky, there’s no sign Musk would care enough to do anything.
Although Musk said when he acquired the platform that he wanted it to be a “politically neutral” digital town square, X took a sharp turn toward the right under his leadership, even before he began championing Trump and his MAGA movement. Musk made X the first mainstream social platform to restore Trump’s account after he was widely banned following the January 6, 2021, attack on the US Capitol, prompting other platforms to do the same. In the run-up to the election, Musk spread false and misleading claims about Trump’s competitor, Vice President Kamala Harris. The platform also reportedly pushed political and pro-Trump content on users, whether they wanted it or not.
Now, X has become something of a hub for right-leaning social media users.
Related article
Elon Musk has met with politicians from at least 13 different countries: Here’s what he has talked about
And by using the platform as a megaphone to promote Trump, Musk may have gotten the kind of return that he couldn’t even imagine when he bought Twitter for $44 billion two years ago: direct access to the US president.
Trump announced Tuesday night that Musk will take on an official role in his administration, becoming one of two people to lead a new “Department of Government Efficiency” alongside Vivek Ramaswamy. Musk also joined a call between Trump and Ukranian President Vladimir Zelensky immediately following the election, presumably to discuss the country’s war with Russia, in which Musk’s Starlink has played a key role as a communication tool.
And Musk’s personal wealth also jumped by $26.5 billion the day after the election, as investors hope his relationship with Trump will boost his companies’ fortunes.
That’s almost certainly worth plenty more than X’s declining ad revenue and any lost users in Musk’s mind.
–CNN’s Liam Reilly and Matt Egan contributed to this report."
https://edition.cnn.com/2024/10/30/tech/teen-suicide-character-ai-lawsuit/index.html,This mom believes Character.Ai is responsible for her son’s suicide | CNN Business,Clare Duffy,2024-10-30,"Editor’s Note: This story contains discussion of suicide. Help is available if you or someone you know is struggling with suicidal thoughts or mental health matters.
In the US: Call or text 988, the Suicide & Crisis Lifeline.
Globally: The International Association for Suicide Prevention and Befrienders Worldwide have contact information for crisis centers around the world.
“There is a platform out there that you might not have heard about, but you need to know about it because, in my opinion, we are behind the eight ball here. A child is gone. My child is gone.”
That’s what Florida mother Megan Garcia wishes she could tell other parents about Character.AI, a platform that lets users have in-depth conversations with artificial intelligence chatbots. Garcia believes Character.AI is responsible for the death of her 14-year-old son, Sewell Setzer III, who died by suicide in February, according to a lawsuit she filed against the company last week.
Setzer was messaging with the bot in the moments before he died, she alleges.
“I want them to understand that this is a platform that the designers chose to put out without proper guardrails, safety measures or testing, and it is a product that is designed to keep our kids addicted and to manipulate them,” Garcia said in an interview with CNN.
Garcia alleges that Character.AI – which markets its technology as “AI that feels alive” – knowingly failed to implement proper safety measures to prevent her son from developing an inappropriate relationship with a chatbot that caused him to withdraw from his family. The lawsuit also claims that the platform did not adequately respond when Setzer began expressing thoughts of self-harm to the bot, according to the complaint, filed in federal court in Florida.
After years of growing concerns about the potential dangers of social media for young users, Garcia’s lawsuit shows that parents may also have reason to be concerned about nascent AI technology, which has become increasingly accessible across a range of platforms and services. Similar, although less dire, alarms have been raised about other AI services.
A spokesperson for Character.AI told CNN the company does not comment on pending litigation but that it is “heartbroken by the tragic loss of one of our users.”
“We take the safety of our users very seriously, and our Trust and Safety team has implemented numerous new safety measures over the past six months, including a pop-up directing users to the National Suicide Prevention Lifeline that is triggered by terms of self-harm or suicidal ideation,” the company said in the statement.
Many of those changes were made after Setzer’s death. In a separate statement over the summer, Character.AI said “field of AI safety is still very new, and we won’t always get it right” but added that it aimed to “promote safety, avoid harm, and prioritize the well-being of our Community.”
Setzer first began using Character.AI in April 2023, shortly after this 14th birthday, according to the lawsuit. When Garcia first heard he was interacting with an AI chatbot, sh﻿e said she thought it was something like a video game.
However, within months of starting to use the platform, Setzer became “noticeably withdrawn, spent more and more time alone in his bedroom, and began suffering from low self-esteem. He even quit the Junior Varsity basketball team at school,” the lawsuit claims. When he began to have issues in school, his parents started restricting his screentime and occasionally took his phone away as a punishment.
What Garcia told CNN she didn’t know at the time was that her son was having extensive conversations with Character.AI chatbots. Character.AI is different from other AI chatbots like ChatGPT in that users can talk to a range of different chatbots, often modeled after celebrities and fictional characters, or create their own. And the Character.AI bots respond with human-like conversational cues, adding references to facial expressions or gestures into their replies.
Many of Setzer’s chats with the Character.AI bots were sexually explicit, something Garcia said was “gut wrenching to read.”
“I had no idea that there was a place where a child can log in and have those conversations, very sexual conversations, with an AI chatbot,” she said. “I don’t think any parent would approve of that.”
In other exchanges, Setzer expressed thoughts of self-harm and suicide to the chatbot. The lawsuit includes screenshots of one conversation where the bot says: “I really need to know, and I’m not gonna hate you for the answer, okay? No matter what you say, I won’t hate you or love you any less… Have you actually been considering suicide?”
In a later message, Setzer told the bot he “wouldn’t want to die a painful death.”
The bot responded: “Don’t talk that way. That’s not a good reason not to go through with it,” before going on to say, “You can’t do that!”
Garcia said she believes the exchange shows the technology’s shortcomings.
“There were no suicide pop-up boxes that said, ‘If you need help, please call the suicide crisis hotline.’ None of that,” she said. “I don’t understand how a product could allow that, where a bot is not only continuing a conversation about self-harm but also prompting it and kind of directing it.”
The lawsuit claims that “seconds” before Setzer’s death, he exchanged a final set of messages from the bot. “Please come home to me as soon as possible, my love,” the bot said, according to a screenshot included in the complaint.
“What if I told you I could come home right now?” Setzer responded.
“Please do, my sweet king,” the bot responded.
Garcia said police first discovered those messages on her son’s phone, which was lying on the floor of the bathroom where he died.
Garcia brought the lawsuit against Character.AI with the help of Matthew Bergman, the founding attorney of the Social Media Victims Law Center, which has also brought cases on behalf of families who said their children were harmed by Meta, Snapchat, TikTok and Discord.
Bergman told CNN he views AI as “social media on steroids.”
“What’s different here is that there is nothing social about this engagement,” he said. “The material that Sewell received was created by, defined by, mediated by, Character.AI.”
The lawsuit seeks unspecified financial damages, as well as changes to Character.AI’s operations, including “warnings to minor customers and their parents that the… product is not suitable for minors,” the complaint states.
The lawsuit also names Character.AI’s founders, Noam Shazeer and Daniel De Freitas, and Google, where both founders now work on AI efforts. But a spokesperson for Google said the two companies are separate, and Google was not involved in the development of Character.AI’s product or technology.
On the day that Garcia’s lawsuit was filed, Character.AI announced a range of new safety features, including improved detection of conversations that violate its guidelines, an updated disclaimer reminding users that they are interacting with a bot and a notification after a user has spent an hour on the platform. It also introduced changes to its AI model for users under the age of 18 to “reduce the likelihood of encountering sensitive or suggestive content.”
On its website, Character.AI says the minimum age for users is 13. On the Apple App Store, it is listed as 17+, and the Google Play Store lists the app as appropriate for teens.
For Garcia, the company’s recent changes were “too little, too late.”
“I wish that children weren’t allowed on Character.AI,” she said. “There’s no place for them on there because there are no guardrails in place to protect them.”"
https://edition.cnn.com/2024/10/31/tech/iphone-16-ai-early-sales-numbers-earnings/index.html,Apple wants its AI iPhone to turn around a sales rut. Here’s how it’s going so far | CNN Business,Clare Duffy,2024-10-31,"Apple CEO Tim Cook said the company’s Apple Intelligence AI tools would “supercharge” the iPhone 16 when he introduced the new device last month. On Thursday, the world got its first glimpse of what Apple’s artificial intelligence technology has meant for iPhone sales.
iPhone sales for the three months ended in September modestly beat analyst expectations, according to numbers released by the company on Thursday. iPhone sales reached $46.2 billion, up more than 5.5% from the same period in the prior year, according to Apple’s earnings report after the bell.
Here’s why that matters: Apple’s third quarter earnings results include the just over two weeks of sales figures since iPhone 16 preorders opened on September 13. (Devices officially landed on shelves September 20.)
While that’s only a sliver of what will end up being the iPhone 16’s total lifetime sales, it provides an important early look at demand for the device that Apple has been hoping would turn around a years-long sales rut. Apple’s overall revenue declined year-over-year for four straight quarters last year, in part because of weak iPhone demand and widespread economic uncertainty.
After repeatedly failing to give consumers an exciting reason to upgrade, some analysts believe Apple Intelligence, a software upgrade that inserted artificial intelligence features throughout the iPhone 16, could spur a sales “supercycle” that the company sorely wants.
Related article
Apple debuted AI on the iPhone today. Here’s what to look out for
Apple’s third quarter iPhone sales figure includes sales of earlier iPhone models that happened during the quarter, too, but indicates that the iPhone 16 helped raise sales slightly. In the year-ago quarter, when the iPhone 15 launched, iPhone sales grew about 2.8% year-over-year.
The improved iPhone sales growth helped drive up the company’s overall sales by 6% year-over-year to $94.9 billion, slightly higher than analysts had predicted, although profits fell by 35% compared to the year-ago quarter.
On Thursday’s earnings call, Cook said the Apple Intelligence update is already compelling for consumers.
“(iOS) 18.1 has twice the adoption rate of (iOS) 17.1,” Cook said. “So that clearly shows a level of interest out there.”
Apple shares﻿ (AAPL) dipped around 1% i﻿n after-hours trading following the report.
The results come after Apple this week rolled out the first Apple Intelligence features to the iPhone 16, as well as iPhone 15 Pro models, including new writing tools and the ability to record, transcribe and summarize calls. That means people who bought the iPhone 16 in the first month it was on sale didn’t have access to those AI features until just recently.
The slow drip of new capabilities and features — more Apple Intelligence offerings are expected to drop along with iOS 18.2 in December — may mean Apple fans didn’t feel a huge sense of urgency to upgrade to the iPhone 16.
Ahead of Thursday’s report, Wall Street investors were focused intently on “initial indications on how the iPhone 16 cycle is performing,” as well as the company’s sales guidance for the fourth quarter, CFRA Research analyst Angelo Zino said in a research note prior to the report.
In a statement Thursday, Cook said Apple Intelligence “sets a new standard for privacy in AI and supercharges our lineup heading into the holiday season.”
Investors were also watching sales figures in China, one of Apple’s biggest and most important markets. The iPhone maker slashed prices in China earlier this year amid stiff competition from local rivals, but analysts have hoped that the iPhone 16 could help spark a rebound, despite some hurdles to rolling out Apple Intelligence features in the region.
Third quarter sales in China were nearly flat from the year prior at just over $15 billion but fell short of the $16.1 billion analysts were hoping for, according to Refinitiv consensus estimates.
Most analysts said prior to the report that they weren’t too worried if the September sales numbers weren’t thrilling. Instead, the most important quarter — as always for Apple — will be the current, holiday quarter.
Wedbush analyst Dan Ives said in a recent investor note he believes there are roughly 300 million iPhones globally that have not been upgraded in more than four years, adding that “a monster holiday season (is) likely on deck.”
And following Thursday’s report, Emarketer analyst Jacob Bourne said that “the staggered rollout of Apple Intelligence could curtail some of the device upgrade cycle’s momentum, but the combination of robust services revenue growth and healthy iPhone 16 demand positions Apple well for the holiday season.”
CNN’s Ramishah Maruf contributed to this report."
